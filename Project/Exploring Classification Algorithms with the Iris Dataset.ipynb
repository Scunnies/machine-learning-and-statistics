{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Classification Algorithms with the Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TABLE OF CONTENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning\n",
    "- What is supervised learning\n",
    "- labelled data\n",
    "- relevance/implementation/importance of supervised learning in machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Iris Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of the Iris Dataset\n",
    "\n",
    "Often referred to as the Fisher Iris Dataset and despite what the name suggests, it was in fact [Edgar Shannon Anderson](https://en.wikipedia.org/wiki/Edgar_Anderson) (1897 - 1969) who, in the 1930s, collected the raw data which formed the basis of the famous iris data set.  Having secured a fellowship to study at the John Innes Horticultural Institute in Britain, Anderson met the statistician [Sir Ronald Aylmer Fisher](https://en.wikipedia.org/wiki/Ronald_Fisher) who went on to published a paper in 1936 proposing a methodological framework to delineate 'desirable' traits based on the Iris dataset and using the statistics originally gathered by Anderson.\n",
    "\n",
    "There are between 200 and 300 species within the [iris](https://sites.berry.edu/cborer/inventory/iris/) genus so identifying them to this particular family can be challenging.  Most irises do have some shared characteristics however, first among them is the presence of six 'petals'. The inner three petals are referred to as “standards” while the outer three sepals, often mistaken for petals, are called “falls”. Sepals serve as protection for the flower in bud and as support for the petals when in bloom.\n",
    "\n",
    "### Attributes of the Iris Data set\n",
    "\n",
    "The [Iris Flower Data Set](https://en.wikipedia.org/wiki/Iris_flower_data_set) represents four measurements of floral morphology on 150 plants - 50 individuals for each of three genus (*Iris versicolor*, *Iris setosa*, and *Iris virginica*).  The numeric parameters which the dataset contains are sepal width, sepal length, petal width and petal length.  Classification accuracy is the ratio of number of correct predictions to the total number of input samples, it works best if there are equal number of samples belonging to each class which, in this case, there are.\n",
    "\n",
    "Each row in the Iris dataset describes one flower for which there are four seperate measurements - the length and width of the sepals and the length and width of the petals.  The 5th column is the species of iris: *setosa, versicolor*, or *virginica*. \n",
    "\n",
    "The Fisher data set is described as the 'Hello World' for machine learning, useful for practicing basic machine learning algorithms.  It endures because the data is open source, the accuracy and origin are both known, it is 'real' data and with three types of flower, it allows for more than just binary classification.  Additionally, with an even 50 in each classification it is balanced and has no null or missing values.  All measurements are on the same scale (cm) so no normalisation is called for and the file size isn’t unwieldy or excessively complicated.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "- load the Iris dataset - scikit-learn\n",
    "- basic statistics and information about the dataset\n",
    "- visualise the dataset using plots (scatter plots, histograms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Algorithms\n",
    "\n",
    "#### What is Classification?\n",
    "- define classification in machine learning\n",
    "- explain goal of classification (assigning labels to data points)\n",
    "\n",
    "#### Common Classification Algorithms\n",
    "- introduce common classification algorithms (Decision Trees, k-Nearest Neighbors, Support Vector Machines, Logistic Regression)\n",
    "- pick one algorithm for detailed exploration [chosen algorithm]\n",
    "\n",
    "#### [chosen algorithm]\n",
    "- explain the concept of [chosen algorithm]\n",
    "- discuss how [chosen algorithm] work for classification\n",
    "- Gini impurity and entropy as criteria for splitting nodes?\n",
    "\n",
    "#### Implementation of [chosen algorithm]\n",
    "- import necessary libraries\n",
    "- split dataset into training and testing sets\n",
    "- create [chosen algorithm] classifier\n",
    "- train the classifier on the training data\n",
    "- evaluate the classifier's performance using accuracy, precision, recall, and F1-score\n",
    "- visualize the [chosen algorithm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "#### Performance Metrics\n",
    "- explain the importance of performance metrics in model evaluation\n",
    "- define accuracy, precision, recall, and F1-score\n",
    "- calculate and interpret metrics for the [chosen algorithm] model\n",
    "\n",
    "#### Confusion Matrix\n",
    "- what is aconfusion matrix\n",
    "- create and visualize the confusion matrix for the [chosen algorithm] model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Classification Algorithms\n",
    "\n",
    "#### Implementing Other Algorithms\n",
    "- choose another classification algorithm for comparison\n",
    "- implement and train selected algorithm\n",
    "- evaluate performance using the same metrics as for [chosen algorithm]\n",
    "\n",
    "#### Model Comparison\n",
    "- compare the performance of the [chosen algorithm] model and the second algorithm\n",
    "- discuss the strengths and weaknesses of each algorithm\n",
    "- consider scenarios - one algorithm preferable over the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
